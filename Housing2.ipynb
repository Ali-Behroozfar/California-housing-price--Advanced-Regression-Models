{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><h2><center> Advanced Regression Techniques / Analysis of house price in California\n",
    "<h3><center>Ali Behroozfar\n",
    "   \n",
    " <br><br>In this project I tried to find the best regression models to explain the housing price in CA. Different regression models were tuned, run and compared with each other. All the data cleaning, visualizations and models evaluations are explained below. The dataset is available online and can be downloaded at this link:<br><br> https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(0)\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of this dataset is : (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of this dataset is : {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It has 6 percent missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058895653644512096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.sum()/df.shape[0]/df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These variables have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "LotFrontage    259\n",
       "Alley         1369\n",
       "MasVnrType       8\n",
       "MasVnrArea       8\n",
       "BsmtQual        37\n",
       "BsmtCond        37\n",
       "BsmtExposure    38\n",
       "BsmtFinType1    37\n",
       "BsmtFinType2    38\n",
       "Electrical       1\n",
       "FireplaceQu    690\n",
       "GarageType      81\n",
       "GarageYrBlt     81\n",
       "GarageFinish    81\n",
       "GarageQual      81\n",
       "GarageCond      81\n",
       "PoolQC        1453\n",
       "Fence         1179\n",
       "MiscFeature   1406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_col = df.isnull().sum()\n",
    "pd.DataFrame(null_col[null_col>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping variables containing high number of missing values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = housing.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice_Log'] = np.log(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "categorical_feats = df.dtypes[df.dtypes == \"object\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
       "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
       "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
       "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns where NaN values have meaning e.g. no pool etc.\n",
    "cols_fillna = ['PoolQC','MiscFeature','Alley','Fence','MasVnrType','FireplaceQu',\n",
    "               'GarageQual','GarageCond','GarageFinish','GarageType', 'Electrical',\n",
    "               'KitchenQual', 'SaleType', 'Functional', 'Exterior2nd', 'Exterior1st',\n",
    "               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2',\n",
    "               'MSZoning', 'Utilities']\n",
    "\n",
    "# replace 'NaN' with 'None' in these columns\n",
    "for col in cols_fillna:\n",
    "    df[col].fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  730.500000\n",
       "MSSubClass           56.897260\n",
       "LotFrontage          70.049958\n",
       "LotArea           10516.828082\n",
       "OverallQual           6.099315\n",
       "OverallCond           5.575342\n",
       "YearBuilt          1971.267808\n",
       "YearRemodAdd       1984.865753\n",
       "MasVnrArea          103.685262\n",
       "BsmtFinSF1          443.639726\n",
       "BsmtFinSF2           46.549315\n",
       "BsmtUnfSF           567.240411\n",
       "TotalBsmtSF        1057.429452\n",
       "1stFlrSF           1162.626712\n",
       "2ndFlrSF            346.992466\n",
       "LowQualFinSF          5.844521\n",
       "GrLivArea          1515.463699\n",
       "BsmtFullBath          0.425342\n",
       "BsmtHalfBath          0.057534\n",
       "FullBath              1.565068\n",
       "HalfBath              0.382877\n",
       "BedroomAbvGr          2.866438\n",
       "KitchenAbvGr          1.046575\n",
       "TotRmsAbvGrd          6.517808\n",
       "Fireplaces            0.613014\n",
       "GarageYrBlt        1978.506164\n",
       "GarageCars            1.767123\n",
       "GarageArea          472.980137\n",
       "WoodDeckSF           94.244521\n",
       "OpenPorchSF          46.660274\n",
       "EnclosedPorch        21.954110\n",
       "3SsnPorch             3.409589\n",
       "ScreenPorch          15.060959\n",
       "PoolArea              2.758904\n",
       "MiscVal              43.489041\n",
       "MoSold                6.321918\n",
       "YrSold             2007.815753\n",
       "SalePrice        180921.195890\n",
       "SalePrice_Log        12.024051\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GrLivArea_Log'] = np.log(df['GrLivArea'])\n",
    "df.drop('GrLivArea', inplace= True, axis = 1)\n",
    "df['LotArea_Log'] = np.log(df['LotArea'])\n",
    "df.drop('LotArea', inplace= True, axis = 1)\n",
    "    \n",
    "numerical_feats = df.dtypes[df.dtypes != \"object\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    df[(df['OverallQual']==10) & (df['SalePrice_Log']<12.3)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    df[(df['GrLivArea_Log']>8.3) & (df['SalePrice_Log']<12.5)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 82)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_drop = ['Id', 'BsmtFinSF1', 'LotFrontage', 'WoodDeckSF', 'OpenPorchSF', '2ndFlrSF', 'HalfBath', 'BsmtFullBath', \n",
    "                  'BsmtUnfSF', 'BedroomAbvGr', 'EnclosedPorch', 'KitchenAbvGr', 'ScreenPorch', 'PoolArea', 'MSSubClass',\n",
    "                  'MoSold','3SsnPorch', 'LowQualFinSF', 'YrSold', 'OverallCond', 'MiscVal', 'Id', 'BsmtHalfBath',\n",
    "                  'BsmtFinSF2', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "                  'Condition1',  'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "                  'ExterCond', 'Foundation', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n",
    "                  'HeatingQC', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                  'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleCondition', 'Condition2', \n",
    "                  'MasVnrType', 'CentralAir', 'Electrical', 'SaleType']\n",
    "df.drop(column_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "msz_catg2 = ['RM', 'RH']\n",
    "msz_catg3 = ['RL', 'FV'] \n",
    "\n",
    "nbhd_catg2 = ['Blmngtn', 'ClearCr', 'CollgCr', 'Crawfor', 'Gilbert', 'NWAmes', 'Somerst', 'Timber', 'Veenker']\n",
    "nbhd_catg3 = ['NoRidge', 'NridgHt', 'StoneBr']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSZ_num'] = 1  \n",
    "df.loc[(df['MSZoning'].isin(msz_catg2) ), 'MSZ_num'] = 2    \n",
    "df.loc[(df['MSZoning'].isin(msz_catg3) ), 'MSZ_num'] = 3        \n",
    "\n",
    "df['NbHd_num'] = 1       \n",
    "df.loc[(df['Neighborhood'].isin(nbhd_catg2) ), 'NbHd_num'] = 2    \n",
    "df.loc[(df['Neighborhood'].isin(nbhd_catg3) ), 'NbHd_num'] = 3    \n",
    "\n",
    "df['ExtQ_num'] = 1       \n",
    "df.loc[(df['ExterQual'] == 'TA' ), 'ExtQ_num'] = 2     \n",
    "df.loc[(df['ExterQual'] == 'Gd' ), 'ExtQ_num'] = 3     \n",
    "df.loc[(df['ExterQual'] == 'Ex' ), 'ExtQ_num'] = 4     \n",
    "\n",
    "df['BsQ_num'] = 1          \n",
    "df.loc[(df['BsmtQual'] == 'Gd' ), 'BsQ_num'] = 2     \n",
    "df.loc[(df['BsmtQual'] == 'Ex' ), 'BsQ_num'] = 3     \n",
    "\n",
    "df['KiQ_num'] = 1       \n",
    "df.loc[(df['KitchenQual'] == 'TA' ), 'KiQ_num'] = 2     \n",
    "df.loc[(df['KitchenQual'] == 'Gd' ), 'KiQ_num'] = 3     \n",
    "df.loc[(df['KitchenQual'] == 'Ex' ), 'KiQ_num'] = 4      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1458 entries, 0 to 1459\n",
      "Data columns (total 26 columns):\n",
      "MSZoning         1458 non-null object\n",
      "Neighborhood     1458 non-null object\n",
      "OverallQual      1458 non-null int64\n",
      "YearBuilt        1458 non-null int64\n",
      "YearRemodAdd     1458 non-null int64\n",
      "MasVnrArea       1458 non-null float64\n",
      "ExterQual        1458 non-null object\n",
      "BsmtQual         1458 non-null object\n",
      "TotalBsmtSF      1458 non-null int64\n",
      "1stFlrSF         1458 non-null int64\n",
      "FullBath         1458 non-null int64\n",
      "KitchenQual      1458 non-null object\n",
      "TotRmsAbvGrd     1458 non-null int64\n",
      "Fireplaces       1458 non-null int64\n",
      "GarageYrBlt      1458 non-null float64\n",
      "GarageCars       1458 non-null int64\n",
      "GarageArea       1458 non-null int64\n",
      "SalePrice        1458 non-null int64\n",
      "SalePrice_Log    1458 non-null float64\n",
      "GrLivArea_Log    1458 non-null float64\n",
      "LotArea_Log      1458 non-null float64\n",
      "MSZ_num          1458 non-null int64\n",
      "NbHd_num         1458 non-null int64\n",
      "ExtQ_num         1458 non-null int64\n",
      "BsQ_num          1458 non-null int64\n",
      "KiQ_num          1458 non-null int64\n",
      "dtypes: float64(5), int64(16), object(5)\n",
      "memory usage: 307.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['SalePrice', 'GarageArea', 'GarageYrBlt', 'TotRmsAbvGrd', '1stFlrSF', 'MSZoning',\n",
    "              'Neighborhood' , 'ExterQual', 'BsmtQual','KitchenQual']\n",
    "df.drop(col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice_Log</th>\n",
       "      <th>GrLivArea_Log</th>\n",
       "      <th>LotArea_Log</th>\n",
       "      <th>MSZ_num</th>\n",
       "      <th>NbHd_num</th>\n",
       "      <th>ExtQ_num</th>\n",
       "      <th>BsQ_num</th>\n",
       "      <th>KiQ_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.247694</td>\n",
       "      <td>7.444249</td>\n",
       "      <td>9.041922</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.109011</td>\n",
       "      <td>7.140453</td>\n",
       "      <td>9.169518</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.317167</td>\n",
       "      <td>7.487734</td>\n",
       "      <td>9.328123</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.849398</td>\n",
       "      <td>7.448334</td>\n",
       "      <td>9.164296</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.429216</td>\n",
       "      <td>7.695303</td>\n",
       "      <td>9.565214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  TotalBsmtSF  FullBath  \\\n",
       "0            7       2003          2003       196.0          856         2   \n",
       "1            6       1976          1976         0.0         1262         2   \n",
       "2            7       2001          2002       162.0          920         2   \n",
       "3            7       1915          1970         0.0          756         1   \n",
       "4            8       2000          2000       350.0         1145         2   \n",
       "\n",
       "   Fireplaces  GarageCars  SalePrice_Log  GrLivArea_Log  LotArea_Log  MSZ_num  \\\n",
       "0           0           2      12.247694       7.444249     9.041922        3   \n",
       "1           1           2      12.109011       7.140453     9.169518        3   \n",
       "2           1           2      12.317167       7.487734     9.328123        3   \n",
       "3           1           3      11.849398       7.448334     9.164296        3   \n",
       "4           1           3      12.429216       7.695303     9.565214        3   \n",
       "\n",
       "   NbHd_num  ExtQ_num  BsQ_num  KiQ_num  \n",
       "0         2         3        2        3  \n",
       "1         2         2        2        2  \n",
       "2         2         3        2        3  \n",
       "3         2         2        1        3  \n",
       "4         3         3        2        3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "sc = MinMaxScaler()\n",
    "val = sc.fit_transform(df.values)\n",
    "df1[df.columns] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>SalePrice_Log</th>\n",
       "      <th>GrLivArea_Log</th>\n",
       "      <th>LotArea_Log</th>\n",
       "      <th>MSZ_num</th>\n",
       "      <th>NbHd_num</th>\n",
       "      <th>ExtQ_num</th>\n",
       "      <th>BsQ_num</th>\n",
       "      <th>KiQ_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.266999</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.581431</td>\n",
       "      <td>0.629245</td>\n",
       "      <td>0.366344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.393637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.536319</td>\n",
       "      <td>0.512191</td>\n",
       "      <td>0.391317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.10125</td>\n",
       "      <td>0.286962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.604029</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.422359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.235808</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.451871</td>\n",
       "      <td>0.630819</td>\n",
       "      <td>0.390295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.725978</td>\n",
       "      <td>0.468761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  TotalBsmtSF  FullBath  \\\n",
       "0     0.666667   0.949275      0.883333     0.12250     0.266999  0.666667   \n",
       "1     0.555556   0.753623      0.433333     0.00000     0.393637  0.666667   \n",
       "2     0.666667   0.934783      0.866667     0.10125     0.286962  0.666667   \n",
       "3     0.666667   0.311594      0.333333     0.00000     0.235808  0.333333   \n",
       "4     0.777778   0.927536      0.833333     0.21875     0.357143  0.666667   \n",
       "\n",
       "   Fireplaces  GarageCars  SalePrice_Log  GrLivArea_Log  LotArea_Log  MSZ_num  \\\n",
       "0    0.000000        0.50       0.581431       0.629245     0.366344      1.0   \n",
       "1    0.333333        0.50       0.536319       0.512191     0.391317      1.0   \n",
       "2    0.333333        0.50       0.604029       0.646000     0.422359      1.0   \n",
       "3    0.333333        0.75       0.451871       0.630819     0.390295      1.0   \n",
       "4    0.333333        0.75       0.640477       0.725978     0.468761      1.0   \n",
       "\n",
       "   NbHd_num  ExtQ_num  BsQ_num   KiQ_num  \n",
       "0       0.5  0.666667      0.5  0.666667  \n",
       "1       0.5  0.333333      0.5  0.333333  \n",
       "2       0.5  0.666667      0.5  0.666667  \n",
       "3       0.5  0.333333      0.0  0.666667  \n",
       "4       1.0  0.666667      0.5  0.666667  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['SalePrice_Log']\n",
    "X = df1.drop(columns=['SalePrice_Log'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,15):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    train_score_array.append(knn_reg.score(X_train, y_train))\n",
    "    test_score_array.append(knn_reg.score(X_test, y_test))\n",
    "\n",
    "x_axis = range(1,15)\n",
    "plt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_array, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8483053873804012\n",
      "0.8232262831609938\n"
     ]
    }
   ],
   "source": [
    "    knn_reg = KNeighborsRegressor(10)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    train_score_array.append(knn_reg.score(X_train, y_train))\n",
    "    test_score_array.append(knn_reg.score(X_test, y_test))\n",
    "    print(knn_reg.score(X_train, y_train))\n",
    "    print(knn_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8874845798922909\n",
      "0.8841954827434313\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train, y_train)\n",
    "print(lreg.score(X_train, y_train))\n",
    "print(lreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8872223565703993\n",
      "0.8833405097061966\n"
     ]
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor(max_iter = 10000, penalty = 'l1')\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "print(sgd_reg.score(X_train, y_train))\n",
    "print(sgd_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02047816])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8874845798922909, 0.9145508036568522]\n",
      "[0.8841954827434308, 0.877355392061856]\n"
     ]
    }
   ],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for n in [1 , 2]:\n",
    "    #polynomialFeatures is an unsupervised learning mode\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    lreg.fit(X_train_poly, y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train))\n",
    "    test_score_list.append(lreg.score(X_test_poly, y_test))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    train_score_list.append(ridge.score(X_train,y_train))\n",
    "    test_score_list.append(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$\\\\alpha$')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_range, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 3)\n",
    "plt.xlabel(r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [0.001, 0.01]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    train_score_list.append(lasso.score(X_train,y_train))\n",
    "    test_score_list.append(lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$\\\\alpha$')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_range, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 3)\n",
    "plt.xlabel(r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859642757307469\n",
      "0.8503953653146945\n"
     ]
    }
   ],
   "source": [
    "svr_lin = SVR(kernel='linear', C=10, gamma=0.1)\n",
    "svr_lin.fit(X_train,y_train)\n",
    "print(svr_lin.score(X_train, y_train))\n",
    "print(svr_lin.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR kernel Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365214082055668\n",
      "0.8016739974799449\n"
     ]
    }
   ],
   "source": [
    "svr_pol = SVR(kernel='poly',C=10, gamma=0.1)\n",
    "svr_pol.fit(X_train,y_train)\n",
    "print(svr_pol.score(X_train, y_train))\n",
    "print(svr_pol.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR kernel rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8528292032075967\n",
      "0.8439555847078803\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=10, gamma=0.1)\n",
    "svr_rbf.fit(X_train,y_train)\n",
    "print(svr_rbf.score(X_train, y_train))\n",
    "print(svr_rbf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828855317150162\n",
      "0.8800728865051283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svm=LinearSVR(tol=0.0001,C=1.0,loss='epsilon_insensitive',fit_intercept=True,intercept_scaling=1.0,\n",
    "    dual=True,verbose=0,max_iter=1000,)\n",
    "linear_svm.fit(X_train,y_train)\n",
    "print(linear_svm.score(X_train, y_train))\n",
    "print(linear_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'fit_intercept': False, 'normalize': True}\n",
      "Best training accuracy: 0.880434\n"
     ]
    }
   ],
   "source": [
    "parameters = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "gs = GridSearchCV(LinearRegression(), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_linear = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.01, 'normalize': True, 'tol': 1e-06}\n",
      "Best training accuracy: 0.880186\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "parameters = {'alpha':[0.001,0.005,0.01,0.1,0.5,1], 'normalize':[True,False], 'tol':[1e-06,5e-06,1e-05,5e-05]}\n",
    "gs = GridSearchCV(ridge, parameters, cv=5,)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_ridge = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.001, 'normalize': False, 'tol': 0.001}\n",
      "Best training accuracy: 0.869622\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':[1e-03,0.01,0.1,0.5,0.8,1], 'normalize':[True,False], 'tol':[1e-06,1e-05,5e-05,1e-04,5e-04,1e-03]}\n",
    "gs = GridSearchCV(Lasso(), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_lasso = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 100, 'gamma': 0.01}\n",
      "Best training accuracy: 0.852136\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_rbf = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'gamma': 0.001}\n",
      "Best training accuracy: 0.853088\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(kernel='linear'), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_linear = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1, 'gamma': 0.1}\n",
      "Best training accuracy: 0.814743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(kernel='poly'), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_poly = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'tol': 0.001}\n",
      "Best training accuracy: 0.877724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'tol':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(LinearSVR(), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_linear_svr = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 1e-05, 'epsilon': 0.001, 'fit_intercept': True, 'max_iter': 10000}\n",
      "Best training accuracy: 0.880035\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_iter' :[10000], 'alpha':[1e-05], 'epsilon':[1e-03, 1e-02, 1e-01], 'fit_intercept' : [True]}\n",
    "gs = GridSearchCV(SGDRegressor(random_state=1250), parameters, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_sgd = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8, 'max_features': 11, 'max_leaf_nodes': None, 'min_samples_split': 20, 'presort': False}\n",
      "Best training accuracy: 0.769035\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'max_depth' : [7,8,9,10] , 'max_features' : [11,12,13,14] ,\n",
    "               'max_leaf_nodes' : [None, 12,15,18,20] ,'min_samples_split' : [20,25,30],\n",
    "                'presort': [False,True]}\n",
    "            \n",
    "gs = GridSearchCV(DecisionTreeRegressor(random_state=1250), param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_dtree = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_split': 4, 'n_estimators': 100}\n",
      "Best training accuracy: 0.860306\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'min_samples_split' : [3,4,6,10], 'n_estimators' : [70,100]}\n",
    "gs = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_rf = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "Best training accuracy: 0.809613\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors' : [3,4,5,6,7,8,10,12,15] ,    \n",
    "              'weights' : ['uniform','distance'] ,\n",
    "              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_knn = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scores = [sc_linear, sc_ridge, sc_lasso, sc_svr_rbf,sc_svr_linear,sc_svr_poly,sc_linear_svr, sc_sgd, sc_dtree, sc_rf, sc_knn]\n",
    "list_regressors = ['Linear','Ridge','Lasso', 'SVR_rbf','SVR_linear','SVR_poly','Linear_SVR', 'SGD','DTr','RF','KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,7)\n",
    "sns.barplot(x=list_regressors, y=list_scores, ax=ax)\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Final Project\n",
    "\n",
    "### Apply any two models with Bagging and any two models with Pasting\n",
    "\n",
    "we applied \"Decision Tree regressor\" and \"KNN regressor\" with bagging \n",
    "            and \n",
    "           \"Decision Tree regressor\" and \"KNN regressor\" with pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858481604039941"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=8, max_features=11, max_leaf_nodes=None, min_samples_split=20, presort=False)\n",
    "bag1 = BaggingRegressor(dt, n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True, random_state=1250)\n",
    "\n",
    "bag1.fit(X_train, y_train)\n",
    "bag1.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214073312454437"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(algorithm= 'brute', n_neighbors=8, weights= 'distance')\n",
    "bag2 = BaggingRegressor(knn, n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True, random_state=1250)\n",
    "\n",
    "bag2.fit(X_train, y_train)\n",
    "bag2.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.938\n",
      "Accuracy on test set: 0.855\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=8, max_features=11, max_leaf_nodes=None, min_samples_split=20, presort=False)\n",
    "paste1 = BaggingRegressor(dt, n_estimators=500, bootstrap=False, n_jobs=-1, random_state=1250)\n",
    "\n",
    "paste1.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(paste1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(paste1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.864\n",
      "Accuracy on test set: 0.854\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(C=100, gamma=0.01)\n",
    "paste2 = BaggingRegressor(svr, n_estimators=500, bootstrap=False, n_jobs=-1, random_state=1250)\n",
    "\n",
    "paste2.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(paste2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(paste2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply any two models with AdaBoost\n",
    "\n",
    "We applied \"Decision Tree regressor\" and \"SVR\" with Adaboost for this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.969\n",
      "Accuracy on test set: 0.881\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=8, max_features=11, max_leaf_nodes=None, min_samples_split=20, presort=False)\n",
    "ada1 = AdaBoostRegressor(dt, n_estimators=500, learning_rate=0.5, random_state=1250)\n",
    "\n",
    "ada1.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(ada1.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(ada1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.847\n",
      "Accuracy on test set: 0.834\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(C=100, gamma=0.01)\n",
    "ada2 = AdaBoostRegressor(svr, n_estimators=500, learning_rate=0.1, random_state=1250)\n",
    "\n",
    "ada2.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(ada2.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(ada2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply one model with Gradient Boosting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=42, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.916\n",
      "Accuracy on test set: 0.893\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "Here, we choose the features which describe 95% of the variations in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53917247, 0.10149298, 0.0671051 , 0.05391313, 0.04945221,\n",
       "       0.0383227 , 0.03637004, 0.02563491, 0.02254668, 0.01737133])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with PCA features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'fit_intercept': True, 'normalize': False}\n",
      "Best training accuracy: 0.857931\n"
     ]
    }
   ],
   "source": [
    "parameters = {'fit_intercept':[True,False], 'normalize':[True,False]}\n",
    "gs = GridSearchCV(LinearRegression(), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_linear_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.5, 'normalize': False, 'tol': 1e-06}\n",
      "Best training accuracy: 0.858008\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "parameters = {'alpha':[0.001,0.005,0.01,0.1,0.5,1], 'normalize':[True,False], 'tol':[1e-06,5e-06,1e-05,5e-05]}\n",
    "gs = GridSearchCV(ridge, parameters, cv=5,)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_ridge_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.001, 'normalize': False, 'tol': 0.0001}\n",
      "Best training accuracy: 0.841758\n"
     ]
    }
   ],
   "source": [
    "parameters = {'alpha':[1e-03,0.01,0.1,0.5,0.8,1], 'normalize':[True,False], 'tol':[1e-06,1e-05,5e-05,1e-04,5e-04,1e-03]}\n",
    "gs = GridSearchCV(Lasso(), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_lasso_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (rbf) with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'gamma': 0.01}\n",
      "Best training accuracy: 0.836626\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_rbf_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (linear) with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'gamma': 0.001}\n",
      "Best training accuracy: 0.835989\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(kernel='linear'), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_linear_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (poly) with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(SVR(kernel='poly'), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_svr_poly_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'tol': 0.001}\n",
      "Best training accuracy: 0.855908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C':[0.001, 0.01, 0.1, 1, 10, 100], 'tol':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "gs = GridSearchCV(LinearSVR(), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_linear_svr_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regressor with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Alex\\Anaconda3.7\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 1e-05, 'epsilon': 0.001, 'fit_intercept': True, 'max_iter': 10000}\n",
      "Best training accuracy: 0.857935\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_iter' :[10000], 'alpha':[1e-05], 'epsilon':[1e-03, 1e-02, 1e-01], 'fit_intercept' : [True]}\n",
    "gs = GridSearchCV(SGDRegressor(random_state=1250), parameters, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_sgd_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regressor with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8, 'max_features': 11, 'max_leaf_nodes': None, 'min_samples_split': 20, 'presort': False}\n",
      "Best training accuracy: 0.769035\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'max_depth' : [7,8,9,10] , 'max_features' : [11,12,13,14] ,\n",
    "               'max_leaf_nodes' : [None, 12,15,18,20] ,'min_samples_split' : [20,25,30],\n",
    "                'presort': [False,True]}\n",
    "            \n",
    "gs = GridSearchCV(DecisionTreeRegressor(random_state=1250), param_grid, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_dtree_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regressor with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best training accuracy: 0.838769\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'min_samples_split' : [3,4,6,10], 'n_estimators' : [70,100]}\n",
    "gs = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_rf_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN regressor with PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "Best training accuracy: 0.805846\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors' : [3,4,5,6,7,8,10,12,15] ,    \n",
    "              'weights' : ['uniform','distance'] ,\n",
    "              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5)\n",
    "gs.fit(X_train_reduced, y_train)\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best training accuracy: {:3f}'.format(gs.best_score_))\n",
    "sc_knn_pca = gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scores = [sc_linear_pca_pca, sc_ridge_pca, sc_lasso_pca, sc_svr_rbf_pca,sc_svr_linear_pca,sc_svr_poly_pca,sc_linear_svr_pca, sc_sgd_pca, sc_dtree_pca, sc_rf_pca, sc_knn_pca]\n",
    "list_regressors = ['Linear','Ridge','Lasso', 'SVR', 'SGD','DTr','RF','KNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The graph below shows the accuracy score of the models mentioned above (with PCA features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,7)\n",
    "sns.barplot(x=list_regressors, y=list_scores, ax=ax)\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8579313480937726,\n",
       " 0.8580079141107247,\n",
       " 0.8417583849488628,\n",
       " 0.8366261901114023,\n",
       " 0.8579346245389348,\n",
       " 0.7690346618584909,\n",
       " 0.838768618428769,\n",
       " 0.8058459614879869]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "  \n",
    "# intialise data of lists. \n",
    "data = {'Model':['KNN', 'Linear Regression', 'SGD regression','Ridge', 'SVM (RBF)','SVM (Linear)','SVM (Poly)'], 'Train Score':[0.7936, 0.8069,0.8069, 0.8059, 0.5384,0.7480,0.0884],'Test Score':[0.7737,\n",
    "0.8175,0.8177,0.8187 ,0.6000,0.7898,0.1314],'Best hyper parameter':['8 nearest neighbour','NA','learning_rate = optimal, penalty = l2','alpha = 1','C=10000,epsilon=0.1','C=10000,epsilon=0.1','C=10000,epsilon=0.1']} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data) \n",
    "  \n",
    "# Print the output. \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for regression\n",
    "\n",
    "#### As can be seen below, a neural network was designed with two hidden layers, 15 inputs (since we have 15 features in the dataset) and 1 output with linear activation unction because the problem is regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1093, 15)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(15, input_dim=15, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 874 samples, validate on 219 samples\n",
      "Epoch 1/200\n",
      "874/874 [==============================] - 2s 2ms/step - loss: 0.4540 - mean_absolute_error: 0.4540 - val_loss: 0.3691 - val_mean_absolute_error: 0.3691\n",
      "Epoch 2/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.2453 - mean_absolute_error: 0.2453 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 3/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0586 - mean_absolute_error: 0.0586 - val_loss: 0.0473 - val_mean_absolute_error: 0.0473\n",
      "Epoch 4/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0469 - mean_absolute_error: 0.0469 - val_loss: 0.0420 - val_mean_absolute_error: 0.0420\n",
      "Epoch 5/200\n",
      "874/874 [==============================] - 0s 48us/step - loss: 0.0423 - mean_absolute_error: 0.0423 - val_loss: 0.0408 - val_mean_absolute_error: 0.0408\n",
      "Epoch 6/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0412 - mean_absolute_error: 0.0412 - val_loss: 0.0383 - val_mean_absolute_error: 0.0383\n",
      "Epoch 7/200\n",
      "874/874 [==============================] - 0s 47us/step - loss: 0.0398 - mean_absolute_error: 0.0398 - val_loss: 0.0382 - val_mean_absolute_error: 0.0382\n",
      "Epoch 8/200\n",
      "874/874 [==============================] - 0s 47us/step - loss: 0.0393 - mean_absolute_error: 0.0393 - val_loss: 0.0362 - val_mean_absolute_error: 0.0362\n",
      "Epoch 9/200\n",
      "874/874 [==============================] - 0s 46us/step - loss: 0.0387 - mean_absolute_error: 0.0387 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
      "Epoch 10/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0383 - mean_absolute_error: 0.0383 - val_loss: 0.0347 - val_mean_absolute_error: 0.0347\n",
      "Epoch 11/200\n",
      "874/874 [==============================] - 0s 43us/step - loss: 0.0376 - mean_absolute_error: 0.0376 - val_loss: 0.0343 - val_mean_absolute_error: 0.0343\n",
      "Epoch 12/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0373 - mean_absolute_error: 0.0373 - val_loss: 0.0345 - val_mean_absolute_error: 0.0345\n",
      "Epoch 13/200\n",
      "874/874 [==============================] - 0s 45us/step - loss: 0.0369 - mean_absolute_error: 0.0369 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
      "Epoch 14/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0365 - mean_absolute_error: 0.0365 - val_loss: 0.0328 - val_mean_absolute_error: 0.0328\n",
      "Epoch 15/200\n",
      "874/874 [==============================] - 0s 45us/step - loss: 0.0361 - mean_absolute_error: 0.0361 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
      "Epoch 16/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0360 - mean_absolute_error: 0.0360 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 17/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0355 - mean_absolute_error: 0.0355 - val_loss: 0.0317 - val_mean_absolute_error: 0.0317\n",
      "Epoch 18/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0359 - mean_absolute_error: 0.0359 - val_loss: 0.0338 - val_mean_absolute_error: 0.0338\n",
      "Epoch 19/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0357 - mean_absolute_error: 0.0357 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
      "Epoch 20/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0353 - mean_absolute_error: 0.0353 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 21/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 22/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 23/200\n",
      "874/874 [==============================] - 0s 48us/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0317 - val_mean_absolute_error: 0.0317\n",
      "Epoch 24/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0340 - mean_absolute_error: 0.0340 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 25/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0339 - mean_absolute_error: 0.0339 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
      "Epoch 26/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0336 - mean_absolute_error: 0.0336 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
      "Epoch 27/200\n",
      "874/874 [==============================] - 0s 48us/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 28/200\n",
      "874/874 [==============================] - 0s 42us/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0315 - val_mean_absolute_error: 0.0315\n",
      "Epoch 29/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 30/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0331 - mean_absolute_error: 0.0331 - val_loss: 0.0325 - val_mean_absolute_error: 0.0325\n",
      "Epoch 31/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "Epoch 32/200\n",
      "874/874 [==============================] - 0s 43us/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 33/200\n",
      "874/874 [==============================] - 0s 43us/step - loss: 0.0333 - mean_absolute_error: 0.0333 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 34/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
      "Epoch 35/200\n",
      "874/874 [==============================] - 0s 43us/step - loss: 0.0330 - mean_absolute_error: 0.0330 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 36/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0301 - val_mean_absolute_error: 0.0301\n",
      "Epoch 37/200\n",
      "874/874 [==============================] - 0s 42us/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 38/200\n",
      "874/874 [==============================] - 0s 43us/step - loss: 0.0328 - mean_absolute_error: 0.0328 - val_loss: 0.0340 - val_mean_absolute_error: 0.0340\n",
      "Epoch 39/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0333 - mean_absolute_error: 0.0333 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 40/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 41/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 42/200\n",
      "874/874 [==============================] - 0s 88us/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 43/200\n",
      "874/874 [==============================] - 0s 81us/step - loss: 0.0330 - mean_absolute_error: 0.0330 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 44/200\n",
      "874/874 [==============================] - 0s 73us/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 45/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0311 - val_mean_absolute_error: 0.0311\n",
      "Epoch 46/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 47/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 48/200\n",
      "874/874 [==============================] - 0s 68us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 49/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 51/200\n",
      "874/874 [==============================] - 0s 76us/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 52/200\n",
      "874/874 [==============================] - 0s 68us/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
      "Epoch 53/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0328 - mean_absolute_error: 0.0328 - val_loss: 0.0318 - val_mean_absolute_error: 0.0318\n",
      "Epoch 54/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 55/200\n",
      "874/874 [==============================] - 0s 74us/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 56/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
      "Epoch 57/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0318 - val_mean_absolute_error: 0.0318\n",
      "Epoch 58/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 59/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
      "Epoch 60/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 61/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0311 - val_mean_absolute_error: 0.0311\n",
      "Epoch 62/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 63/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0400 - val_mean_absolute_error: 0.0400\n",
      "Epoch 64/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0362 - mean_absolute_error: 0.0362 - val_loss: 0.0314 - val_mean_absolute_error: 0.0314\n",
      "Epoch 65/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 66/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 67/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 68/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 69/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 70/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 71/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
      "Epoch 72/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 73/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0336 - mean_absolute_error: 0.0336 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 74/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
      "Epoch 75/200\n",
      "874/874 [==============================] - 0s 70us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 76/200\n",
      "874/874 [==============================] - 0s 67us/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 77/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 78/200\n",
      "874/874 [==============================] - 0s 68us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 79/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0290 - val_mean_absolute_error: 0.0290\n",
      "Epoch 80/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0308 - val_mean_absolute_error: 0.0308\n",
      "Epoch 81/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0330 - val_mean_absolute_error: 0.0330\n",
      "Epoch 82/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0289 - val_mean_absolute_error: 0.0289\n",
      "Epoch 83/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 84/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 85/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 86/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 87/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0328 - mean_absolute_error: 0.0328 - val_loss: 0.0323 - val_mean_absolute_error: 0.0323\n",
      "Epoch 88/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 89/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
      "Epoch 90/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
      "Epoch 91/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 92/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 93/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0321 - val_mean_absolute_error: 0.0321\n",
      "Epoch 94/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 95/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 96/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 97/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 98/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874/874 [==============================] - 0s 55us/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
      "Epoch 100/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0330 - val_mean_absolute_error: 0.0330\n",
      "Epoch 101/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 102/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 103/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 104/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 105/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 106/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 107/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0306 - val_mean_absolute_error: 0.0306\n",
      "Epoch 108/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 109/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 110/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 111/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 112/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 113/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0311 - val_mean_absolute_error: 0.0311\n",
      "Epoch 114/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n",
      "Epoch 115/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 116/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 117/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 118/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 119/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0316 - val_mean_absolute_error: 0.0316\n",
      "Epoch 120/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 121/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n",
      "Epoch 122/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0312 - val_mean_absolute_error: 0.0312\n",
      "Epoch 123/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
      "Epoch 124/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 125/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 126/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 127/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 128/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 129/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0301 - val_mean_absolute_error: 0.0301\n",
      "Epoch 130/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 131/200\n",
      "874/874 [==============================] - 0s 105us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0301 - val_mean_absolute_error: 0.0301\n",
      "Epoch 132/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 133/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 134/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 135/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 136/200\n",
      "874/874 [==============================] - 0s 67us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 137/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0345 - val_mean_absolute_error: 0.0345\n",
      "Epoch 138/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 139/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 140/200\n",
      "874/874 [==============================] - 0s 67us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 141/200\n",
      "874/874 [==============================] - 0s 54us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 142/200\n",
      "874/874 [==============================] - 0s 50us/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358\n",
      "Epoch 143/200\n",
      "874/874 [==============================] - 0s 49us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 144/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 145/200\n",
      "874/874 [==============================] - 0s 51us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 146/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0314 - val_mean_absolute_error: 0.0314\n",
      "Epoch 147/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0337 - val_mean_absolute_error: 0.0337\n",
      "Epoch 149/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 150/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 151/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0304 - mean_absolute_error: 0.0304 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 152/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 153/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 154/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0323 - val_mean_absolute_error: 0.0323\n",
      "Epoch 155/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 156/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 157/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 158/200\n",
      "874/874 [==============================] - 0s 67us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 159/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
      "Epoch 160/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 161/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 162/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0348 - val_mean_absolute_error: 0.0348\n",
      "Epoch 163/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 164/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
      "Epoch 165/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 166/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0345 - val_mean_absolute_error: 0.0345\n",
      "Epoch 167/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 168/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 169/200\n",
      "874/874 [==============================] - 0s 52us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0352 - val_mean_absolute_error: 0.0352\n",
      "Epoch 170/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 171/200\n",
      "874/874 [==============================] - 0s 65us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 172/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
      "Epoch 173/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 174/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 175/200\n",
      "874/874 [==============================] - 0s 67us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 176/200\n",
      "874/874 [==============================] - 0s 82us/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 177/200\n",
      "874/874 [==============================] - 0s 71us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 178/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 179/200\n",
      "874/874 [==============================] - 0s 62us/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0324 - val_mean_absolute_error: 0.0324\n",
      "Epoch 180/200\n",
      "874/874 [==============================] - 0s 82us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 181/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0315 - val_mean_absolute_error: 0.0315\n",
      "Epoch 182/200\n",
      "874/874 [==============================] - 0s 64us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 183/200\n",
      "874/874 [==============================] - 0s 66us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0298 - val_mean_absolute_error: 0.0298\n",
      "Epoch 184/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 185/200\n",
      "874/874 [==============================] - 0s 59us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0301 - val_mean_absolute_error: 0.0301\n",
      "Epoch 186/200\n",
      "874/874 [==============================] - 0s 60us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0305 - val_mean_absolute_error: 0.0305\n",
      "Epoch 187/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 188/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0308 - val_mean_absolute_error: 0.0308\n",
      "Epoch 189/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0313 - val_mean_absolute_error: 0.0313\n",
      "Epoch 190/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 191/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0310 - val_mean_absolute_error: 0.0310\n",
      "Epoch 192/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 193/200\n",
      "874/874 [==============================] - 0s 63us/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 194/200\n",
      "874/874 [==============================] - 0s 87us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 195/200\n",
      "874/874 [==============================] - 0s 56us/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0297 - val_mean_absolute_error: 0.0297\n",
      "Epoch 196/200\n",
      "874/874 [==============================] - 0s 55us/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "874/874 [==============================] - 0s 57us/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "Epoch 198/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 199/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0295 - val_mean_absolute_error: 0.0295\n",
      "Epoch 200/200\n",
      "874/874 [==============================] - 0s 58us/step - loss: 0.0303 - mean_absolute_error: 0.0303 - val_loss: 0.0304 - val_mean_absolute_error: 0.0304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233e8e58ef0>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=50, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KERAS doesnt give R squared score so we wrote a progrm as shown below to claculate the R squared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice_Log    0.881813\n",
       "dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_test_df=y_test.to_frame()\n",
    "SS_res=((y_test_df-predictions)**2).sum()\n",
    "SS_tot=(((y_test_df-(y_test_df).mean()))**2).sum()\n",
    "1 - SS_res/(SS_tot + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As can be seen above, the acuracy score of this NN for the housing problem test set is 0.881813 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
